readtoken(STDIN)
12.
error
readtoken(STDIN)
readtoken(STDIN)
readtoken(STDIN)
'\'''
'\''
readtoken(STDIN)
12.3
readtoken(STDIN)
12.3
readtoken(STDIN)
12.3
readtoken(STDIN)
.23
readtoken(STDIN)
212.
readtoken(STDIN)
2
readtoken(STDIN)
a,
readfile
acc = []
push!(acc, 2)
push!(acc, 2)
readfile("test.txt")
bool(2)
Bool(12)
readfile("test.txt")
readfile("test.txt")
readfile("test.txt")
readfile("test.txt")
readfile("test.txt")
readfile("test.txt")
readfile("test.txt")
readfile("test.txt")
'\n'
string("a", '\n')
print(string("a", '\n'))
readfile("test.txt")
readfile("test.txt")
readfile("test.txt")
{1,2}
{1 }
{
2 3 4}
{a=>2}
{a=>2}
readfile("test.txt")
readfile("test.txt")
readfile("test.txt")
readfile("test.txt")
readfile("test.txt")
readfile("test.txt")
readfile("test.txt")
readfile("test.txt")
readfile("test.txt")
readfile("test.txt")
"foo" in ["foo"]
readfile("test.txt")
readlines
?readlines
readlines(STDIN)
aaab
bbb
readlines("test.txt")
readlines("test.txt")
eachline
?eachline
eachline("test.txt")
a = eachline("test.txt")
a.stream
collect(a)
a
for x in s
for x in a ; print(x) end
a
functionloc
?functionloc
functionloc(eachline, IO)
functionloc(eachline, (IO,))
eachtoken
1
eachtoken("test.txt")
for x in eachtoken("test.txt")
print(x)
end
for x in eachtoken("test.txt")
print(x)
end
quit()
for x in eachtoken("test.txt")
print(x)
end
for x in eachtoken("test.txt")
print(x)
end
for x in eachtoken("test.txt")
print(x)
end
readtokens
readlines
?readlines
readtokens
readtokens("test.txt")
SizeUnknown()
Base.SizeUnknown()
readtokens("test.txt")
quit 8
quit()
readtokens("test.txt")
readuntil
?readuntil
LispNil
LispNil()
typeof(LispNil())
typeof(LispNil)
LispLexer
LispLexer.Token
LispLexer.eachtoken
LispLexer.eachtoken("test.txt")
collect(LispLexer.eachtoken("test.txt"))
LOAD_PATH
quit()
eachtoken
eachtoken
LispLexer.eachtoken
LispLexer.eachtoken
LispParser.hoge()
LispParser.hoge()
LispParser.hoge()[1]
LispParser.hoge()[1].kind
LispParser.hoge()[1].value
LispParser.hoge()[1].info
parse
?parse
Pair
Nil
Nil
Obj
using LispParser
Obj
LispParser
LispParser.Obj
LispParser.Cons(LispParser.Obj(:a, "b"), LispParser.Obj(:a, "b"))
pair = LispParser.Cons(LispParser.Obj(:a, "b"), LispParser.Obj(:a, "b"))
LispParser.Cons(pair, pair)
cons
cons(1,2)
cons
cons(1,2)
Obj
Cons
quit()
using LispParser
using LispParser
Cons
cons
*
importall LispParser
Obj
cons(1,2)
using LispParser
cons
cons(1,2)
nil = Obj(:nil, "")
nil = LispParser.Obj(:nil, "")
nil
cons(nil, nil)
using LispParser
nil = LispParser.Obj(:nil, "")
cons(nil, nil)
using LispParser
nil = LispParser.Obj(:nil, "")
cons(nil, nil)
nil = Obj(:nil, "")
cons(nil, nil)
cons
 methods(cons)
parse
2
3
quit()
1
cons
cons(1,2)
nil = Obj(:nil, false)
nil
cons(nil, nil)
cons(nil, nil)
cons(nil, nil)
Enum
Enum(a,2)
Enum(3,2)
LispLexer.tokenkinds
["(", 1, 2, 3 ")"]
["(", 1, 2, 3, ")"]
["(", "(", 1, 2, 3, ")", ")"]
[1,2,3]
[1,2,3][1:]
[1,2,3][1:end]
[1,2,3][2:end]
[]
isnull([])
isempty([])
first
first[1,23]
first([1,23])
?first
last
rest
rest([1,2,3])
?rest 
2
readtoken
readtoken
readtoken
readtoken
quit()
1
readtoken
Pkg.add("PEGParser")
Pkg.update()
Pkg.add("PEGParser")
readline()
aao
readline()
1
readtokens("test.txt")
using LispLexer
readtokens("test.txt")
readtokens
quit()
readtokens
readtokens("test.txt")
readtokens("test.txt")
readtokens("test.txt")
chop("\n")
chop("\n")
chomp("\n")
?chomp
?chop
quit()
readtokens("test.txt")
Token
LispLexer.Token
LispLexer.Token(1,2)
LispLexer.Token(:a, "fo")
currenttoken("test.txt")
position(STDIN)
a
open("test.txt") do pos ; position(pos) end
readtoken("test.txt")
readtokens("test.txt")
quit()
readtokens("test.txt")
eachtoken("test.txt")
collect(eachtoken("test.txt"))
collect(eachtoken("test.txt"))
collect(eachtoken("test.txt"))
collect(eachtoken("test.txt"))
collect(eachtoken("test.txt"))
collect(eachtoken("test.txt"))
(c::Char)->(c)
(c::Char)->(c)('a')
((c::Char)->(c))('a')
quit()
collect(eachtoken("test.txt"))
quit()
collect(eachtoken("test.txt"))
collect(eachtoken("test.txt"))
quit()
collect(eachtoken("test.txt"))
quit()
collect(eachtoken("test.txt"))
open("test.txt") do s
loopy(s)
end
print(1,2,3)
open("test.txt") do s
loopy(s)
end
tokenkinds
LispLexer.tokenkinds
quit 8
quit()
LispLexer.tokenkinds
quit()
collect(eachtoken("test.txt"))
readtoken(STDIN)
12.3
loopy(open("test.txt"))
loopy(open("test.txt"))
loopy(open("test.txt"))
loopy(open("test.txt"))
loopy(open("test.txt"))
loopy(open("test.txt"))
loopy(open("test.txt"))
collect(eachtoken("test.txt"))
quit()
collect(eachtoken("test.txt"))
collect(eachtoken("test.txt"))
data
list
vector
Lexer
LispLexer
LispLexer.lexer
LispLexer.lexer("test.txt")
collect(LispLexer.lexer("test.txt"))
lex = LispLexer.lexer("test.txt")
lex.currenttoken
lex.stream
lex.currenttoken
lex = LispLexer.lexer("test.txt")
lex.currenttoken
lex
lex.stream
lex.ondone
lex = LispLexer.lexer("test.txt")
lex.currenttoken
readtoken(lex)
LispLexer.readtoken(lex)
LispLexer.readtoken(lex)
lex.currenttoken
read
Base.read
read(lexer("test.txt"))
read(LispLexer.lexer)("test.txt")
Base.read(LispLexer.lexer)("test.txt")
Base.read(LispLexer.lexer)("test.txt")
Base.read(LispLexer.lexer("test.txt"))
Base.read(LispLexer.lexer("test.txt"))
Base.read(LispLexer.lexer("test.txt"))
read(LispLexer.lexer("test.txt"))
seek
1
data(lexer("test.txt"))
data(lexer("test.txt"))
lexer
quit()
lexer
data(lexer("test.txt"))
data(lexer("test.txt"))
quit()
data(lexer("test.txt"))
data(lexer("test.txt"))
lexer("test.txt")
collect(lexer("test.txt"))
collect(lexer("test.txt"))
seek(lexer("test.txt"))
seek(lexer("test.txt"))
seek(lexer("test.txt"))
lex = lexer("test.txt")
seek(lex)
seek(lex)
seek(lex)
read(lex)
read(lex)
read(lex)
read(lex)
read(lex)
read(lex)
read(lex)
read(lex)
read(lex)
match
LispLexer.Token
LispLexer.Token(:a, "b")
LispLexer.Token(:a, "b") ==  LispLexer.Token(:a, "b")
consume
Lexer
lexer
quit()
lexer
Lexer
Lexer
Token
lex = lexer("test.txt")
match_read(lex, :open)
match_read(lex, :open)
lex = lexer("test.txt")
seek(lex)
seek(lex)
read(lex)
read(lex)
read(lex)
read(lex)
read(lex)
read(lex)
lex = lexer("test.txt")
lex
lex.currenttoken
seek(lex)
seek(lex)
seek(lex)
lex
lex
quit()
1
lex = lexer("test.txt")
seek(lex)
quit()
lex = lexer("test.txt")
seek(lex)
quit()
lex = lexer("test.txt")
seek(lex)
seek(lex)
read(lex)
read(lex)
seek(lex)
seek(lex)
seek(lex)
seek(lex)
?read
methods(read)
quit 8
quit()
lex = lexer("test.txt")
currenttoken(lex)
currenttoken(lex)
readtoken(lex)
readtoken(lex)
currenttoken(lex)
currenttoken(lex)
currenttoken(lex)
currenttoken(lex)
lex = lexer("test.txt")
match_readtoken(lex, :open)
currenttoken(lex)
currenttoken(lex)
currenttoken(lex)
readtoken(lex)
currenttoken(lex)
quit()
lex = lexer("test.txt")
match_readtoken(lex, :open)
match_readtoken(lex, :start)
currenttoken(lex)
currenttoken(lex)
quit 8
quit()
1
lex =  lexer("test.txt")
currenttoken(lex)
current_
current_task
currenttoken(lex)
currenttoken(lex)
quit()
lex =  lexer("test.txt")
currenttoken(lex)
match_readtoken(lex, "(")
match_readtoken(lex, :open)
currenttoken(lex)
readtoken(lex)
readtoken(lex)
readtoken(lex)
readtoken(lex)
readtoken(lex)
readtoken(lex)
lex =  lexer("test.txt")
collect(lex)
quit()
1
lex = lexer("test.txt")
quit()
lex = lexer("test.txt")
lex
currenttoken(lex)
readtoken(lex)
data(lex)
lex = lexer("test.txt")
readtoken(lex)
currenttoken(lex)
data(lex)
lex = lexer("test.txt")
currenttoken(lex)
readtoken(lex)
data(lex)
lex = lexer("test.txt")
readtoken(lex)
data(lex)
lex = lexer("test.txt")
lex = lexer("test.txt"); readtoken(lex); data(lex)
lex = lexer("test.txt"); readtoken(lex); data(lex)
lex = lexer("test.txt"); readtoken(lex); data(lex)
lex = lexer("test.txt"); readtoken(lex); data(lex)
lexer
lexer(STDIN)
stdin
STDIN
parent(STDIN)
parent(typeof(STDIN))
typeof(STDIN)
parent
?parent
parent(Base.TTY)
